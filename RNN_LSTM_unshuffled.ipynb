{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime as dt\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "cpi = pd.read_csv(\"resources/cpi_final.csv\")\n",
    "gdp = pd.read_csv(\"resources/gdp_final.csv\")\n",
    "gdp_pct = pd.read_csv(\"resources/gdp_pct_chg_final.csv\")\n",
    "houst = pd.read_csv(\"resources/housing_starts_final.csv\")\n",
    "opg = pd.read_csv(\"resources/output_gap_final.csv\")\n",
    "rec_dt = pd.read_csv(\"resources/recession_dates_final.csv\")\n",
    "unrate = pd.read_csv(\"resources/unemployment_rate_final.csv\")\n",
    "fed_funds = pd.read_csv(\"resources/fed_funds_final.csv\")\n",
    "yield10_2 = pd.read_csv(\"resources/10YT_minus_2YT_final.csv\")\n",
    "fred = pd.read_csv(\"resources/FRED_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all data sets into one data frame\n",
    "dfs = [cpi, gdp, gdp_pct, houst, opg, rec_dt, unrate, fed_funds, yield10_2, fred]\n",
    "df = reduce(lambda left,right: pd.merge(left,right,on=['quarter'],how='outer'), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop date columns\n",
    "df = df.drop(columns=['date_x','date_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data frame by quarter\n",
    "df = df.sort_values(by=['quarter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset before removing nulls\n",
    "# df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>avg_consumer_price_index</th>\n",
       "      <th>gdp</th>\n",
       "      <th>gdp_pct_change</th>\n",
       "      <th>avg_housing_starts</th>\n",
       "      <th>output_gap</th>\n",
       "      <th>target</th>\n",
       "      <th>avg_unemployment_rate</th>\n",
       "      <th>fed_funds_avg_rate</th>\n",
       "      <th>fed_funds_percent_change_prev_quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>10YT_minus_2YT_percent_change_prev_quarter</th>\n",
       "      <th>real_disp_pers_inc</th>\n",
       "      <th>personal_consumption_exp_excl_food_energy</th>\n",
       "      <th>cpi_US_total</th>\n",
       "      <th>tot_public_debt_as_pct_of_gdp</th>\n",
       "      <th>gross_private_domestic_invest</th>\n",
       "      <th>M2_velocity</th>\n",
       "      <th>median_sls_price_houses_sold_US</th>\n",
       "      <th>nat_rate_of_unemp_long_term</th>\n",
       "      <th>personal_consumption_expenditures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>2018Q1</td>\n",
       "      <td>249.250333</td>\n",
       "      <td>20163.159</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1320.666667</td>\n",
       "      <td>0.202456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1.448966</td>\n",
       "      <td>0.204683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113861</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.214194</td>\n",
       "      <td>104.59493</td>\n",
       "      <td>3542.412</td>\n",
       "      <td>1.451</td>\n",
       "      <td>331800.0</td>\n",
       "      <td>4.597</td>\n",
       "      <td>13728.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>2018Q2</td>\n",
       "      <td>250.578667</td>\n",
       "      <td>20510.177</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1259.666667</td>\n",
       "      <td>0.589182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>1.727176</td>\n",
       "      <td>0.192007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.251397</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.711887</td>\n",
       "      <td>103.33928</td>\n",
       "      <td>3561.592</td>\n",
       "      <td>1.461</td>\n",
       "      <td>315600.0</td>\n",
       "      <td>4.592</td>\n",
       "      <td>13939.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>2018Q3</td>\n",
       "      <td>251.828667</td>\n",
       "      <td>20749.752</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1233.000000</td>\n",
       "      <td>0.821959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>1.923492</td>\n",
       "      <td>0.113663</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.432836</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.640940</td>\n",
       "      <td>103.69309</td>\n",
       "      <td>3683.981</td>\n",
       "      <td>1.462</td>\n",
       "      <td>330900.0</td>\n",
       "      <td>4.587</td>\n",
       "      <td>14114.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>2018Q4</td>\n",
       "      <td>252.759000</td>\n",
       "      <td>20897.804</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1185.000000</td>\n",
       "      <td>0.592021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>2.217097</td>\n",
       "      <td>0.152641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078947</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.203131</td>\n",
       "      <td>105.15026</td>\n",
       "      <td>3725.234</td>\n",
       "      <td>1.462</td>\n",
       "      <td>322800.0</td>\n",
       "      <td>4.582</td>\n",
       "      <td>14211.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>2019Q1</td>\n",
       "      <td>253.311333</td>\n",
       "      <td>21098.827</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1213.000000</td>\n",
       "      <td>0.848147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.133333</td>\n",
       "      <td>2.401311</td>\n",
       "      <td>0.083088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.271429</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.644936</td>\n",
       "      <td>104.40334</td>\n",
       "      <td>3783.364</td>\n",
       "      <td>1.458</td>\n",
       "      <td>313000.0</td>\n",
       "      <td>4.577</td>\n",
       "      <td>14266.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    quarter  avg_consumer_price_index        gdp  gdp_pct_change  \\\n",
       "284  2018Q1                249.250333  20163.159             5.0   \n",
       "285  2018Q2                250.578667  20510.177             7.1   \n",
       "286  2018Q3                251.828667  20749.752             4.8   \n",
       "287  2018Q4                252.759000  20897.804             2.9   \n",
       "288  2019Q1                253.311333  21098.827             3.9   \n",
       "\n",
       "     avg_housing_starts  output_gap  target  avg_unemployment_rate  \\\n",
       "284         1320.666667    0.202456     0.0               4.333333   \n",
       "285         1259.666667    0.589182     0.0               3.833333   \n",
       "286         1233.000000    0.821959     0.0               3.866667   \n",
       "287         1185.000000    0.592021     0.0               3.566667   \n",
       "288         1213.000000    0.848147     0.0               4.133333   \n",
       "\n",
       "     fed_funds_avg_rate  fed_funds_percent_change_prev_quarter  ...  \\\n",
       "284            1.448966                               0.204683  ...   \n",
       "285            1.727176                               0.192007  ...   \n",
       "286            1.923492                               0.113663  ...   \n",
       "287            2.217097                               0.152641  ...   \n",
       "288            2.401311                               0.083088  ...   \n",
       "\n",
       "     10YT_minus_2YT_percent_change_prev_quarter  real_disp_pers_inc  \\\n",
       "284                                   -0.113861                 6.9   \n",
       "285                                   -0.251397                 2.7   \n",
       "286                                   -0.432836                 3.3   \n",
       "287                                   -0.078947                 2.8   \n",
       "288                                   -0.271429                 4.5   \n",
       "\n",
       "     personal_consumption_exp_excl_food_energy  cpi_US_total  \\\n",
       "284                                        1.8      2.214194   \n",
       "285                                        2.0      2.711887   \n",
       "286                                        2.0      2.640940   \n",
       "287                                        1.9      2.203131   \n",
       "288                                        1.6      1.644936   \n",
       "\n",
       "     tot_public_debt_as_pct_of_gdp  gross_private_domestic_invest  \\\n",
       "284                      104.59493                       3542.412   \n",
       "285                      103.33928                       3561.592   \n",
       "286                      103.69309                       3683.981   \n",
       "287                      105.15026                       3725.234   \n",
       "288                      104.40334                       3783.364   \n",
       "\n",
       "     M2_velocity  median_sls_price_houses_sold_US  \\\n",
       "284        1.451                         331800.0   \n",
       "285        1.461                         315600.0   \n",
       "286        1.462                         330900.0   \n",
       "287        1.462                         322800.0   \n",
       "288        1.458                         313000.0   \n",
       "\n",
       "     nat_rate_of_unemp_long_term  personal_consumption_expenditures  \n",
       "284                        4.597                          13728.357  \n",
       "285                        4.592                          13939.828  \n",
       "286                        4.587                          14114.559  \n",
       "287                        4.582                          14211.920  \n",
       "288                        4.577                          14266.250  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataset after removing nulls\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index to quarter\n",
    "df = df.set_index('quarter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_consumer_price_index</th>\n",
       "      <th>gdp</th>\n",
       "      <th>gdp_pct_change</th>\n",
       "      <th>avg_housing_starts</th>\n",
       "      <th>output_gap</th>\n",
       "      <th>recession_actual</th>\n",
       "      <th>avg_unemployment_rate</th>\n",
       "      <th>fed_funds_avg_rate</th>\n",
       "      <th>fed_funds_percent_change_prev_quarter</th>\n",
       "      <th>fed_funds_st_dev_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>10YT_minus_2YT_percent_change_prev_quarter</th>\n",
       "      <th>real_disp_pers_inc</th>\n",
       "      <th>personal_consumption_exp_excl_food_energy</th>\n",
       "      <th>cpi_US_total</th>\n",
       "      <th>tot_public_debt_as_pct_of_gdp</th>\n",
       "      <th>gross_private_domestic_invest</th>\n",
       "      <th>M2_velocity</th>\n",
       "      <th>median_sls_price_houses_sold_US</th>\n",
       "      <th>nat_rate_of_unemp_long_term</th>\n",
       "      <th>personal_consumption_expenditures</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quarter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1976Q3</th>\n",
       "      <td>57.300000</td>\n",
       "      <td>1886.558</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1557.000000</td>\n",
       "      <td>-2.199151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>5.283478</td>\n",
       "      <td>0.016956</td>\n",
       "      <td>0.100618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370833</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.518087</td>\n",
       "      <td>33.64333</td>\n",
       "      <td>328.307</td>\n",
       "      <td>1.717</td>\n",
       "      <td>44400.0</td>\n",
       "      <td>6.217</td>\n",
       "      <td>1158.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976Q4</th>\n",
       "      <td>58.133333</td>\n",
       "      <td>1934.273</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1691.333333</td>\n",
       "      <td>-2.246705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>4.874239</td>\n",
       "      <td>-0.077456</td>\n",
       "      <td>0.211941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337386</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.069403</td>\n",
       "      <td>33.78753</td>\n",
       "      <td>337.650</td>\n",
       "      <td>1.699</td>\n",
       "      <td>45500.0</td>\n",
       "      <td>6.223</td>\n",
       "      <td>1192.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977Q1</th>\n",
       "      <td>59.200000</td>\n",
       "      <td>1988.648</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1844.333333</td>\n",
       "      <td>-1.877175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.233333</td>\n",
       "      <td>4.660667</td>\n",
       "      <td>-0.043817</td>\n",
       "      <td>0.148254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095455</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.857741</td>\n",
       "      <td>33.65136</td>\n",
       "      <td>360.313</td>\n",
       "      <td>1.689</td>\n",
       "      <td>46300.0</td>\n",
       "      <td>6.227</td>\n",
       "      <td>1228.212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977Q2</th>\n",
       "      <td>60.233333</td>\n",
       "      <td>2055.909</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1918.666667</td>\n",
       "      <td>-0.776696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.933333</td>\n",
       "      <td>5.157473</td>\n",
       "      <td>0.106595</td>\n",
       "      <td>0.332835</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052764</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.847698</td>\n",
       "      <td>32.80422</td>\n",
       "      <td>389.703</td>\n",
       "      <td>1.701</td>\n",
       "      <td>48900.0</td>\n",
       "      <td>6.232</td>\n",
       "      <td>1255.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977Q3</th>\n",
       "      <td>61.066667</td>\n",
       "      <td>2118.473</td>\n",
       "      <td>12.7</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>0.186001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>5.816413</td>\n",
       "      <td>0.127764</td>\n",
       "      <td>0.344309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.342175</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.682162</td>\n",
       "      <td>32.98791</td>\n",
       "      <td>414.134</td>\n",
       "      <td>1.713</td>\n",
       "      <td>48800.0</td>\n",
       "      <td>6.235</td>\n",
       "      <td>1286.905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_consumer_price_index       gdp  gdp_pct_change  \\\n",
       "quarter                                                       \n",
       "1976Q3                  57.300000  1886.558             7.6   \n",
       "1976Q4                  58.133333  1934.273            10.5   \n",
       "1977Q1                  59.200000  1988.648            11.7   \n",
       "1977Q2                  60.233333  2055.909            14.2   \n",
       "1977Q3                  61.066667  2118.473            12.7   \n",
       "\n",
       "         avg_housing_starts  output_gap  recession_actual  \\\n",
       "quarter                                                     \n",
       "1976Q3          1557.000000   -2.199151               0.0   \n",
       "1976Q4          1691.333333   -2.246705               0.0   \n",
       "1977Q1          1844.333333   -1.877175               0.0   \n",
       "1977Q2          1918.666667   -0.776696               0.0   \n",
       "1977Q3          2009.000000    0.186001               0.0   \n",
       "\n",
       "         avg_unemployment_rate  fed_funds_avg_rate  \\\n",
       "quarter                                              \n",
       "1976Q3                7.600000            5.283478   \n",
       "1976Q4                7.333333            4.874239   \n",
       "1977Q1                8.233333            4.660667   \n",
       "1977Q2                6.933333            5.157473   \n",
       "1977Q3                6.800000            5.816413   \n",
       "\n",
       "         fed_funds_percent_change_prev_quarter  fed_funds_st_dev_rate  ...  \\\n",
       "quarter                                                                ...   \n",
       "1976Q3                                0.016956               0.100618  ...   \n",
       "1976Q4                               -0.077456               0.211941  ...   \n",
       "1977Q1                               -0.043817               0.148254  ...   \n",
       "1977Q2                                0.106595               0.332835  ...   \n",
       "1977Q3                                0.127764               0.344309  ...   \n",
       "\n",
       "         10YT_minus_2YT_percent_change_prev_quarter  real_disp_pers_inc  \\\n",
       "quarter                                                                   \n",
       "1976Q3                                     0.370833                 3.2   \n",
       "1976Q4                                     0.337386                 2.6   \n",
       "1977Q1                                    -0.095455                 0.9   \n",
       "1977Q2                                    -0.052764                 3.8   \n",
       "1977Q3                                    -0.342175                 5.7   \n",
       "\n",
       "         personal_consumption_exp_excl_food_energy  cpi_US_total  \\\n",
       "quarter                                                            \n",
       "1976Q3                                         6.0      5.518087   \n",
       "1976Q4                                         6.0      5.069403   \n",
       "1977Q1                                         6.2      5.857741   \n",
       "1977Q2                                         6.5      6.847698   \n",
       "1977Q3                                         6.6      6.682162   \n",
       "\n",
       "         tot_public_debt_as_pct_of_gdp  gross_private_domestic_invest  \\\n",
       "quarter                                                                 \n",
       "1976Q3                        33.64333                        328.307   \n",
       "1976Q4                        33.78753                        337.650   \n",
       "1977Q1                        33.65136                        360.313   \n",
       "1977Q2                        32.80422                        389.703   \n",
       "1977Q3                        32.98791                        414.134   \n",
       "\n",
       "         M2_velocity  median_sls_price_houses_sold_US  \\\n",
       "quarter                                                 \n",
       "1976Q3         1.717                          44400.0   \n",
       "1976Q4         1.699                          45500.0   \n",
       "1977Q1         1.689                          46300.0   \n",
       "1977Q2         1.701                          48900.0   \n",
       "1977Q3         1.713                          48800.0   \n",
       "\n",
       "         nat_rate_of_unemp_long_term  personal_consumption_expenditures  \n",
       "quarter                                                                  \n",
       "1976Q3                         6.217                           1158.806  \n",
       "1976Q4                         6.223                           1192.408  \n",
       "1977Q1                         6.227                           1228.212  \n",
       "1977Q2                         6.232                           1255.980  \n",
       "1977Q3                         6.235                           1286.905  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename target column\n",
    "df = df.rename(columns={'target':'recession_actual'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift data with sliding window technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['recession_1q_out'] = df['recession_actual'].shift(-1)\n",
    "df['recession_2q_out'] = df['recession_actual'].shift(-2)\n",
    "df['recession_4q_out'] = df['recession_actual'].shift(-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create three datasets -- 1 for each model (recession 1Qtr out, 2Qtrs out, 4Qtrs out)\n",
    "df_q1 = df.drop(columns=['recession_2q_out','recession_4q_out','recession_actual'])\n",
    "df_q2 = df.drop(columns=['recession_4q_out','recession_1q_out','recession_actual'])\n",
    "df_q4 = df.drop(columns=['recession_1q_out','recession_2q_out','recession_actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete missing values\n",
    "df_q1 = df_q1.dropna()\n",
    "df_q2 = df_q2.dropna()\n",
    "df_q4 = df_q4.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y variables\n",
    "y1 = df_q1['recession_1q_out']\n",
    "y2 = df_q2['recession_2q_out']\n",
    "y3 = df_q4['recession_4q_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop target\n",
    "df_q1 = df_q1.drop(columns=['recession_1q_out'])\n",
    "df_q2 = df_q2.drop(columns=['recession_2q_out'])\n",
    "df_q4 = df_q4.drop(columns=['recession_4q_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X\n",
    "X_q1 = df_q1\n",
    "X_q2 = df_q2\n",
    "X_q4 = df_q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing (stratify=None, shuffle=False)\n",
    "X1_train, X1_test, y1_train, y1_test=train_test_split(X_q1, y1, train_size=0.8, random_state=42, shuffle=False)\n",
    "X2_train, X2_test, y2_train, y2_test=train_test_split(X_q2, y2, train_size=0.8, random_state=42, shuffle=False)\n",
    "X3_train, X3_test, y3_train, y3_test=train_test_split(X_q4, y3, train_size=0.8, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create scaler object\n",
    "X1_scaler = StandardScaler().fit(X1_train)\n",
    "X2_scaler = StandardScaler().fit(X2_train)\n",
    "X3_scaler = StandardScaler().fit(X3_train)\n",
    "\n",
    "# X full scaler\n",
    "X1_full_scaler = StandardScaler().fit(X_q1)\n",
    "X2_full_scaler = StandardScaler().fit(X_q2)\n",
    "X3_full_scaler = StandardScaler().fit(X_q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale training data\n",
    "X1_train_scaled = X1_scaler.transform(X1_train)\n",
    "X2_train_scaled = X2_scaler.transform(X2_train)\n",
    "X3_train_scaled = X3_scaler.transform(X3_train)\n",
    "\n",
    "# Scale testing data\n",
    "X1_test_scaled = X1_scaler.transform(X1_test)\n",
    "X2_test_scaled = X2_scaler.transform(X2_test)\n",
    "X3_test_scaled = X3_scaler.transform(X3_test)\n",
    "\n",
    "# Scale full X data (no splits)\n",
    "X1_full_scaled = X1_full_scaler.transform(X_q1)\n",
    "X2_full_scaled = X2_full_scaler.transform(X_q2)\n",
    "X3_full_scaled = X3_full_scaler.transform(X_q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape data to fit LSTM format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to reshape data\n",
    "def reshape_data(obj):\n",
    "    reshaped_obj = np.reshape(obj, (obj.shape[0], obj.shape[1], 1))\n",
    "    return reshaped_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape training data\n",
    "reshaped_X1_train_scaled = reshape_data(X1_train_scaled)\n",
    "reshaped_X2_train_scaled = reshape_data(X2_train_scaled)\n",
    "reshaped_X3_train_scaled = reshape_data(X3_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape testing data\n",
    "reshaped_X1_test_scaled = reshape_data(X1_test_scaled)\n",
    "reshaped_X2_test_scaled = reshape_data(X2_test_scaled)\n",
    "reshaped_X3_test_scaled = reshape_data(X3_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X_full\n",
    "reshaped_X1_full = reshape_data(X1_full_scaled)\n",
    "reshaped_X2_full = reshape_data(X2_full_scaled)\n",
    "reshaped_X3_full = reshape_data(X3_full_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Add layers\n",
    "model.add(LSTM(128, input_shape=(reshaped_X1_train_scaled.shape[1],1), return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())  # Normalize activation outputs\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and predict on X1-Y1 data (recession 1 quarter out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 108 samples, validate on 28 samples\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "108/108 - 16s - loss: 0.9347 - acc: 0.5093 - val_loss: 0.6840 - val_acc: 0.7500\n",
      "Epoch 2/100\n",
      "108/108 - 2s - loss: 0.6631 - acc: 0.6667 - val_loss: 0.6751 - val_acc: 0.7500\n",
      "Epoch 3/100\n",
      "108/108 - 2s - loss: 0.6772 - acc: 0.6667 - val_loss: 0.6656 - val_acc: 0.7500\n",
      "Epoch 4/100\n",
      "108/108 - 2s - loss: 0.4941 - acc: 0.7222 - val_loss: 0.6542 - val_acc: 0.7500\n",
      "Epoch 5/100\n",
      "108/108 - 2s - loss: 0.5376 - acc: 0.7407 - val_loss: 0.6432 - val_acc: 0.7500\n",
      "Epoch 6/100\n",
      "108/108 - 2s - loss: 0.5351 - acc: 0.7037 - val_loss: 0.6324 - val_acc: 0.7500\n",
      "Epoch 7/100\n",
      "108/108 - 2s - loss: 0.3947 - acc: 0.8148 - val_loss: 0.6239 - val_acc: 0.7500\n",
      "Epoch 8/100\n",
      "108/108 - 2s - loss: 0.4372 - acc: 0.8426 - val_loss: 0.6143 - val_acc: 0.7500\n",
      "Epoch 9/100\n",
      "108/108 - 2s - loss: 0.4535 - acc: 0.7778 - val_loss: 0.6068 - val_acc: 0.7500\n",
      "Epoch 10/100\n",
      "108/108 - 2s - loss: 0.4990 - acc: 0.7315 - val_loss: 0.6020 - val_acc: 0.7500\n",
      "Epoch 11/100\n",
      "108/108 - 2s - loss: 0.4516 - acc: 0.7500 - val_loss: 0.5968 - val_acc: 0.7500\n",
      "Epoch 12/100\n",
      "108/108 - 2s - loss: 0.4472 - acc: 0.8148 - val_loss: 0.5920 - val_acc: 0.7500\n",
      "Epoch 13/100\n",
      "108/108 - 2s - loss: 0.4267 - acc: 0.7778 - val_loss: 0.5902 - val_acc: 0.7500\n",
      "Epoch 14/100\n",
      "108/108 - 2s - loss: 0.3809 - acc: 0.8241 - val_loss: 0.5905 - val_acc: 0.7500\n",
      "Epoch 15/100\n",
      "108/108 - 2s - loss: 0.3841 - acc: 0.8056 - val_loss: 0.5893 - val_acc: 0.7500\n",
      "Epoch 16/100\n",
      "108/108 - 2s - loss: 0.4214 - acc: 0.7778 - val_loss: 0.5889 - val_acc: 0.7500\n",
      "Epoch 17/100\n",
      "108/108 - 2s - loss: 0.4152 - acc: 0.7500 - val_loss: 0.5918 - val_acc: 0.7500\n",
      "Epoch 18/100\n",
      "108/108 - 2s - loss: 0.3821 - acc: 0.8148 - val_loss: 0.5916 - val_acc: 0.7500\n",
      "Epoch 19/100\n",
      "108/108 - 2s - loss: 0.3997 - acc: 0.8148 - val_loss: 0.5868 - val_acc: 0.7500\n",
      "Epoch 20/100\n",
      "108/108 - 2s - loss: 0.4503 - acc: 0.8148 - val_loss: 0.5754 - val_acc: 0.7500\n",
      "Epoch 21/100\n",
      "108/108 - 2s - loss: 0.3758 - acc: 0.8519 - val_loss: 0.5638 - val_acc: 0.7500\n",
      "Epoch 22/100\n",
      "108/108 - 2s - loss: 0.4180 - acc: 0.7778 - val_loss: 0.5554 - val_acc: 0.7500\n",
      "Epoch 23/100\n",
      "108/108 - 2s - loss: 0.3755 - acc: 0.8426 - val_loss: 0.5536 - val_acc: 0.7500\n",
      "Epoch 24/100\n",
      "108/108 - 2s - loss: 0.3492 - acc: 0.8426 - val_loss: 0.5516 - val_acc: 0.7500\n",
      "Epoch 25/100\n",
      "108/108 - 2s - loss: 0.3393 - acc: 0.8426 - val_loss: 0.5519 - val_acc: 0.7500\n",
      "Epoch 26/100\n",
      "108/108 - 2s - loss: 0.3416 - acc: 0.8426 - val_loss: 0.5517 - val_acc: 0.7500\n",
      "Epoch 27/100\n",
      "108/108 - 2s - loss: 0.3954 - acc: 0.8241 - val_loss: 0.5417 - val_acc: 0.7500\n",
      "Epoch 28/100\n",
      "108/108 - 2s - loss: 0.2660 - acc: 0.8704 - val_loss: 0.5304 - val_acc: 0.7500\n",
      "Epoch 29/100\n",
      "108/108 - 2s - loss: 0.2942 - acc: 0.8611 - val_loss: 0.5243 - val_acc: 0.7500\n",
      "Epoch 30/100\n",
      "108/108 - 2s - loss: 0.3477 - acc: 0.8426 - val_loss: 0.5256 - val_acc: 0.7500\n",
      "Epoch 31/100\n",
      "108/108 - 2s - loss: 0.2971 - acc: 0.8241 - val_loss: 0.5364 - val_acc: 0.7500\n",
      "Epoch 32/100\n",
      "108/108 - 2s - loss: 0.3380 - acc: 0.8241 - val_loss: 0.5514 - val_acc: 0.7500\n",
      "Epoch 33/100\n",
      "108/108 - 2s - loss: 0.3273 - acc: 0.8611 - val_loss: 0.5664 - val_acc: 0.7500\n",
      "Epoch 34/100\n",
      "108/108 - 2s - loss: 0.2636 - acc: 0.8519 - val_loss: 0.5715 - val_acc: 0.7500\n",
      "Epoch 35/100\n",
      "108/108 - 2s - loss: 0.2821 - acc: 0.8796 - val_loss: 0.5661 - val_acc: 0.7500\n",
      "Epoch 36/100\n",
      "108/108 - 2s - loss: 0.2765 - acc: 0.8704 - val_loss: 0.5666 - val_acc: 0.7500\n",
      "Epoch 37/100\n",
      "108/108 - 2s - loss: 0.2609 - acc: 0.8796 - val_loss: 0.5739 - val_acc: 0.7500\n",
      "Epoch 38/100\n",
      "108/108 - 2s - loss: 0.2504 - acc: 0.8889 - val_loss: 0.5783 - val_acc: 0.6786\n",
      "Epoch 39/100\n",
      "108/108 - 2s - loss: 0.1980 - acc: 0.9259 - val_loss: 0.5828 - val_acc: 0.6786\n",
      "Epoch 40/100\n",
      "108/108 - 2s - loss: 0.2253 - acc: 0.8704 - val_loss: 0.5760 - val_acc: 0.7143\n",
      "Epoch 41/100\n",
      "108/108 - 2s - loss: 0.2830 - acc: 0.8241 - val_loss: 0.5768 - val_acc: 0.6786\n",
      "Epoch 42/100\n",
      "108/108 - 2s - loss: 0.2404 - acc: 0.8704 - val_loss: 0.5657 - val_acc: 0.7143\n",
      "Epoch 43/100\n",
      "108/108 - 2s - loss: 0.2238 - acc: 0.8889 - val_loss: 0.5783 - val_acc: 0.7143\n",
      "Epoch 44/100\n",
      "108/108 - 2s - loss: 0.2442 - acc: 0.8611 - val_loss: 0.6081 - val_acc: 0.7143\n",
      "Epoch 45/100\n",
      "108/108 - 2s - loss: 0.2192 - acc: 0.8889 - val_loss: 0.6900 - val_acc: 0.6071\n",
      "Epoch 46/100\n",
      "108/108 - 2s - loss: 0.1884 - acc: 0.9352 - val_loss: 0.7442 - val_acc: 0.6071\n",
      "Epoch 47/100\n",
      "108/108 - 2s - loss: 0.2154 - acc: 0.8981 - val_loss: 0.7970 - val_acc: 0.6071\n",
      "Epoch 48/100\n",
      "108/108 - 2s - loss: 0.2269 - acc: 0.8981 - val_loss: 0.8006 - val_acc: 0.5714\n",
      "Epoch 49/100\n",
      "108/108 - 2s - loss: 0.2742 - acc: 0.8704 - val_loss: 0.7933 - val_acc: 0.5357\n",
      "Epoch 50/100\n",
      "108/108 - 2s - loss: 0.2405 - acc: 0.8796 - val_loss: 0.7483 - val_acc: 0.5714\n",
      "Epoch 51/100\n",
      "108/108 - 2s - loss: 0.1730 - acc: 0.9444 - val_loss: 0.7282 - val_acc: 0.5714\n",
      "Epoch 52/100\n",
      "108/108 - 2s - loss: 0.2238 - acc: 0.8981 - val_loss: 0.7397 - val_acc: 0.5714\n",
      "Epoch 53/100\n",
      "108/108 - 2s - loss: 0.2152 - acc: 0.9074 - val_loss: 0.7367 - val_acc: 0.5714\n",
      "Epoch 54/100\n",
      "108/108 - 2s - loss: 0.1852 - acc: 0.8981 - val_loss: 0.7704 - val_acc: 0.5357\n",
      "Epoch 55/100\n",
      "108/108 - 2s - loss: 0.2218 - acc: 0.8981 - val_loss: 0.7916 - val_acc: 0.5714\n",
      "Epoch 56/100\n",
      "108/108 - 2s - loss: 0.1621 - acc: 0.9259 - val_loss: 0.7724 - val_acc: 0.5357\n",
      "Epoch 57/100\n",
      "108/108 - 2s - loss: 0.2000 - acc: 0.8889 - val_loss: 0.7969 - val_acc: 0.5714\n",
      "Epoch 58/100\n",
      "108/108 - 2s - loss: 0.1717 - acc: 0.9444 - val_loss: 0.8393 - val_acc: 0.5357\n",
      "Epoch 59/100\n",
      "108/108 - 2s - loss: 0.2076 - acc: 0.8796 - val_loss: 1.0090 - val_acc: 0.3214\n",
      "Epoch 60/100\n",
      "108/108 - 2s - loss: 0.1557 - acc: 0.9259 - val_loss: 1.1286 - val_acc: 0.3214\n",
      "Epoch 61/100\n",
      "108/108 - 2s - loss: 0.2175 - acc: 0.9167 - val_loss: 1.1703 - val_acc: 0.2857\n",
      "Epoch 62/100\n",
      "108/108 - 2s - loss: 0.1438 - acc: 0.9352 - val_loss: 1.1642 - val_acc: 0.2857\n",
      "Epoch 63/100\n",
      "108/108 - 2s - loss: 0.1263 - acc: 0.9630 - val_loss: 1.1223 - val_acc: 0.3214\n",
      "Epoch 64/100\n",
      "108/108 - 2s - loss: 0.1360 - acc: 0.9630 - val_loss: 1.1198 - val_acc: 0.3214\n",
      "Epoch 65/100\n",
      "108/108 - 2s - loss: 0.1312 - acc: 0.9444 - val_loss: 1.1146 - val_acc: 0.3571\n",
      "Epoch 66/100\n",
      "108/108 - 2s - loss: 0.1266 - acc: 0.9537 - val_loss: 1.1339 - val_acc: 0.3571\n",
      "Epoch 67/100\n",
      "108/108 - 2s - loss: 0.1284 - acc: 0.9444 - val_loss: 1.1417 - val_acc: 0.3571\n",
      "Epoch 68/100\n",
      "108/108 - 2s - loss: 0.1718 - acc: 0.9259 - val_loss: 1.2223 - val_acc: 0.3214\n",
      "Epoch 69/100\n",
      "108/108 - 2s - loss: 0.1507 - acc: 0.9074 - val_loss: 1.4205 - val_acc: 0.2500\n",
      "Epoch 70/100\n",
      "108/108 - 2s - loss: 0.1599 - acc: 0.9074 - val_loss: 1.5060 - val_acc: 0.2143\n",
      "Epoch 71/100\n",
      "108/108 - 2s - loss: 0.1235 - acc: 0.9444 - val_loss: 1.5444 - val_acc: 0.2143\n",
      "Epoch 72/100\n",
      "108/108 - 2s - loss: 0.1166 - acc: 0.9722 - val_loss: 1.5075 - val_acc: 0.2143\n",
      "Epoch 73/100\n",
      "108/108 - 2s - loss: 0.1112 - acc: 0.9630 - val_loss: 1.4779 - val_acc: 0.2143\n",
      "Epoch 74/100\n",
      "108/108 - 2s - loss: 0.1299 - acc: 0.9352 - val_loss: 1.4041 - val_acc: 0.2857\n",
      "Epoch 75/100\n",
      "108/108 - 2s - loss: 0.1531 - acc: 0.9444 - val_loss: 1.2530 - val_acc: 0.2857\n",
      "Epoch 76/100\n",
      "108/108 - 2s - loss: 0.1240 - acc: 0.9630 - val_loss: 1.0440 - val_acc: 0.4643\n",
      "Epoch 77/100\n",
      "108/108 - 2s - loss: 0.0999 - acc: 0.9630 - val_loss: 0.9080 - val_acc: 0.6429\n",
      "Epoch 78/100\n",
      "108/108 - 2s - loss: 0.0625 - acc: 0.9907 - val_loss: 0.8788 - val_acc: 0.6071\n",
      "Epoch 79/100\n",
      "108/108 - 2s - loss: 0.0846 - acc: 0.9815 - val_loss: 0.9101 - val_acc: 0.6429\n",
      "Epoch 80/100\n",
      "108/108 - 2s - loss: 0.1140 - acc: 0.9444 - val_loss: 0.9920 - val_acc: 0.6071\n",
      "Epoch 81/100\n",
      "108/108 - 2s - loss: 0.1087 - acc: 0.9630 - val_loss: 1.0827 - val_acc: 0.6071\n",
      "Epoch 82/100\n",
      "108/108 - 2s - loss: 0.0793 - acc: 0.9815 - val_loss: 1.1172 - val_acc: 0.6071\n",
      "Epoch 83/100\n",
      "108/108 - 2s - loss: 0.0873 - acc: 0.9722 - val_loss: 1.1351 - val_acc: 0.5714\n",
      "Epoch 84/100\n",
      "108/108 - 2s - loss: 0.0897 - acc: 0.9630 - val_loss: 1.1438 - val_acc: 0.5357\n",
      "Epoch 85/100\n",
      "108/108 - 2s - loss: 0.0476 - acc: 0.9907 - val_loss: 1.1481 - val_acc: 0.5000\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 - 2s - loss: 0.0832 - acc: 0.9815 - val_loss: 1.1384 - val_acc: 0.4643\n",
      "Epoch 87/100\n",
      "108/108 - 2s - loss: 0.1321 - acc: 0.9352 - val_loss: 1.1238 - val_acc: 0.5357\n",
      "Epoch 88/100\n",
      "108/108 - 2s - loss: 0.1027 - acc: 0.9630 - val_loss: 1.0854 - val_acc: 0.5000\n",
      "Epoch 89/100\n",
      "108/108 - 2s - loss: 0.0864 - acc: 0.9630 - val_loss: 0.9211 - val_acc: 0.6071\n",
      "Epoch 90/100\n",
      "108/108 - 2s - loss: 0.1126 - acc: 0.9722 - val_loss: 0.9103 - val_acc: 0.6071\n",
      "Epoch 91/100\n",
      "108/108 - 2s - loss: 0.0954 - acc: 0.9630 - val_loss: 0.9496 - val_acc: 0.5714\n",
      "Epoch 92/100\n",
      "108/108 - 2s - loss: 0.0934 - acc: 0.9630 - val_loss: 1.1126 - val_acc: 0.5357\n",
      "Epoch 93/100\n",
      "108/108 - 2s - loss: 0.0809 - acc: 0.9722 - val_loss: 1.2468 - val_acc: 0.5000\n",
      "Epoch 94/100\n",
      "108/108 - 2s - loss: 0.0732 - acc: 0.9815 - val_loss: 1.3348 - val_acc: 0.4643\n",
      "Epoch 95/100\n",
      "108/108 - 2s - loss: 0.0684 - acc: 1.0000 - val_loss: 1.3977 - val_acc: 0.4286\n",
      "Epoch 96/100\n",
      "108/108 - 2s - loss: 0.1160 - acc: 0.9722 - val_loss: 1.3318 - val_acc: 0.4643\n",
      "Epoch 97/100\n",
      "108/108 - 2s - loss: 0.0671 - acc: 0.9815 - val_loss: 1.2753 - val_acc: 0.4643\n",
      "Epoch 98/100\n",
      "108/108 - 2s - loss: 0.0656 - acc: 0.9907 - val_loss: 1.2044 - val_acc: 0.5357\n",
      "Epoch 99/100\n",
      "108/108 - 2s - loss: 0.0864 - acc: 0.9444 - val_loss: 1.1816 - val_acc: 0.5000\n",
      "Epoch 100/100\n",
      "108/108 - 2s - loss: 0.0821 - acc: 0.9630 - val_loss: 1.1201 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a484dab00>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(reshaped_X1_train_scaled, y1_train, validation_split=0.2, epochs=100, shuffle=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 - 0s - loss: 0.1257 - acc: 0.9412\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "model_loss1, model_accuracy1 = model.evaluate(reshaped_X1_test_scaled, y1_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using test data\n",
    "predictions1 = model.predict_classes(reshaped_X1_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "one_qtr_out = pd.DataFrame({\"Predicted\":predictions1, \"Actual\":y1_test})\n",
    "# one_qtr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "name1 = f\"unshuffled-1q-out-{dt.datetime.now()}\"\n",
    "model.save(f\"models/{name1}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on full X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X1_full = model.predict_classes(reshaped_X1_full)\n",
    "\n",
    "# Preview results\n",
    "X1_full_results = pd.DataFrame({\"Predicted\":pred_X1_full, \"Actual\":y1})\n",
    "# X1_full_results.loc[X1_full_results[\"Actual\"]==1]\n",
    "\n",
    "# Export results for graphing\n",
    "X1_full_results.to_csv(f\"resources/predictions/X1_full_unshuffled_{dt.datetime.now()}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix on X1-Y1 data (recession 1 quarter out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32  2]\n",
      " [ 0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix on X1 model\n",
    "con_mat = confusion_matrix(y1_test, predictions1)\n",
    "print(con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.94      0.97        34\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.94        34\n",
      "   macro avg       0.50      0.47      0.48        34\n",
      "weighted avg       1.00      0.94      0.97        34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Score model\n",
    "print(classification_report(y1_test, predictions1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and predict on X2-Y2 data (recession 2 quarters out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 108 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "108/108 - 2s - loss: 0.3638 - acc: 0.9074 - val_loss: 1.2643 - val_acc: 0.4444\n",
      "Epoch 2/100\n",
      "108/108 - 2s - loss: 0.2451 - acc: 0.9259 - val_loss: 1.4562 - val_acc: 0.4444\n",
      "Epoch 3/100\n",
      "108/108 - 2s - loss: 0.1438 - acc: 0.9352 - val_loss: 1.8528 - val_acc: 0.3704\n",
      "Epoch 4/100\n",
      "108/108 - 2s - loss: 0.2058 - acc: 0.9259 - val_loss: 2.1940 - val_acc: 0.2222\n",
      "Epoch 5/100\n",
      "108/108 - 2s - loss: 0.1258 - acc: 0.9444 - val_loss: 2.0669 - val_acc: 0.2963\n",
      "Epoch 6/100\n",
      "108/108 - 2s - loss: 0.1435 - acc: 0.9167 - val_loss: 1.7376 - val_acc: 0.3704\n",
      "Epoch 7/100\n",
      "108/108 - 2s - loss: 0.1205 - acc: 0.9444 - val_loss: 1.5341 - val_acc: 0.4815\n",
      "Epoch 8/100\n",
      "108/108 - 2s - loss: 0.0825 - acc: 0.9815 - val_loss: 1.4467 - val_acc: 0.4815\n",
      "Epoch 9/100\n",
      "108/108 - 2s - loss: 0.1156 - acc: 0.9537 - val_loss: 1.3789 - val_acc: 0.5556\n",
      "Epoch 10/100\n",
      "108/108 - 2s - loss: 0.0832 - acc: 0.9722 - val_loss: 1.3687 - val_acc: 0.5185\n",
      "Epoch 11/100\n",
      "108/108 - 2s - loss: 0.0823 - acc: 0.9722 - val_loss: 1.4142 - val_acc: 0.5185\n",
      "Epoch 12/100\n",
      "108/108 - 2s - loss: 0.0666 - acc: 0.9815 - val_loss: 1.4456 - val_acc: 0.4074\n",
      "Epoch 13/100\n",
      "108/108 - 2s - loss: 0.0796 - acc: 0.9722 - val_loss: 1.4448 - val_acc: 0.4815\n",
      "Epoch 14/100\n",
      "108/108 - 2s - loss: 0.0892 - acc: 0.9630 - val_loss: 1.4307 - val_acc: 0.4815\n",
      "Epoch 15/100\n",
      "108/108 - 2s - loss: 0.0860 - acc: 0.9815 - val_loss: 1.4660 - val_acc: 0.4815\n",
      "Epoch 16/100\n",
      "108/108 - 2s - loss: 0.0548 - acc: 0.9907 - val_loss: 1.4926 - val_acc: 0.4815\n",
      "Epoch 17/100\n",
      "108/108 - 2s - loss: 0.0590 - acc: 0.9815 - val_loss: 1.4935 - val_acc: 0.4815\n",
      "Epoch 18/100\n",
      "108/108 - 2s - loss: 0.0784 - acc: 0.9722 - val_loss: 1.4721 - val_acc: 0.4815\n",
      "Epoch 19/100\n",
      "108/108 - 2s - loss: 0.0618 - acc: 0.9815 - val_loss: 1.4573 - val_acc: 0.5185\n",
      "Epoch 20/100\n",
      "108/108 - 2s - loss: 0.0703 - acc: 0.9630 - val_loss: 1.6416 - val_acc: 0.4815\n",
      "Epoch 21/100\n",
      "108/108 - 2s - loss: 0.0392 - acc: 1.0000 - val_loss: 1.7603 - val_acc: 0.5185\n",
      "Epoch 22/100\n",
      "108/108 - 2s - loss: 0.0709 - acc: 0.9722 - val_loss: 1.7694 - val_acc: 0.5185\n",
      "Epoch 23/100\n",
      "108/108 - 2s - loss: 0.0425 - acc: 0.9907 - val_loss: 1.6778 - val_acc: 0.4815\n",
      "Epoch 24/100\n",
      "108/108 - 2s - loss: 0.0600 - acc: 0.9722 - val_loss: 1.7454 - val_acc: 0.4815\n",
      "Epoch 25/100\n",
      "108/108 - 2s - loss: 0.0310 - acc: 1.0000 - val_loss: 1.8539 - val_acc: 0.4815\n",
      "Epoch 26/100\n",
      "108/108 - 2s - loss: 0.0518 - acc: 0.9907 - val_loss: 1.8784 - val_acc: 0.4815\n",
      "Epoch 27/100\n",
      "108/108 - 2s - loss: 0.0566 - acc: 0.9815 - val_loss: 1.9890 - val_acc: 0.4444\n",
      "Epoch 28/100\n",
      "108/108 - 2s - loss: 0.0676 - acc: 0.9630 - val_loss: 2.0172 - val_acc: 0.4074\n",
      "Epoch 29/100\n",
      "108/108 - 2s - loss: 0.0396 - acc: 0.9907 - val_loss: 2.0251 - val_acc: 0.3704\n",
      "Epoch 30/100\n",
      "108/108 - 2s - loss: 0.0789 - acc: 0.9815 - val_loss: 1.8784 - val_acc: 0.4074\n",
      "Epoch 31/100\n",
      "108/108 - 2s - loss: 0.0673 - acc: 0.9630 - val_loss: 1.7383 - val_acc: 0.5926\n",
      "Epoch 32/100\n",
      "108/108 - 2s - loss: 0.0575 - acc: 0.9815 - val_loss: 1.7220 - val_acc: 0.6296\n",
      "Epoch 33/100\n",
      "108/108 - 2s - loss: 0.0407 - acc: 0.9907 - val_loss: 1.7575 - val_acc: 0.6667\n",
      "Epoch 34/100\n",
      "108/108 - 2s - loss: 0.0541 - acc: 0.9722 - val_loss: 1.8058 - val_acc: 0.6667\n",
      "Epoch 35/100\n",
      "108/108 - 2s - loss: 0.0262 - acc: 0.9907 - val_loss: 1.8529 - val_acc: 0.6296\n",
      "Epoch 36/100\n",
      "108/108 - 2s - loss: 0.0346 - acc: 0.9907 - val_loss: 1.9053 - val_acc: 0.6296\n",
      "Epoch 37/100\n",
      "108/108 - 2s - loss: 0.0425 - acc: 0.9722 - val_loss: 1.9940 - val_acc: 0.5556\n",
      "Epoch 38/100\n",
      "108/108 - 2s - loss: 0.0293 - acc: 0.9907 - val_loss: 2.0573 - val_acc: 0.5185\n",
      "Epoch 39/100\n",
      "108/108 - 2s - loss: 0.0229 - acc: 1.0000 - val_loss: 2.0731 - val_acc: 0.5185\n",
      "Epoch 40/100\n",
      "108/108 - 2s - loss: 0.0279 - acc: 0.9907 - val_loss: 2.0637 - val_acc: 0.5185\n",
      "Epoch 41/100\n",
      "108/108 - 2s - loss: 0.0343 - acc: 1.0000 - val_loss: 1.9906 - val_acc: 0.5926\n",
      "Epoch 42/100\n",
      "108/108 - 2s - loss: 0.0329 - acc: 0.9815 - val_loss: 1.9368 - val_acc: 0.6296\n",
      "Epoch 43/100\n",
      "108/108 - 2s - loss: 0.0309 - acc: 0.9907 - val_loss: 1.8322 - val_acc: 0.5926\n",
      "Epoch 44/100\n",
      "108/108 - 2s - loss: 0.0223 - acc: 1.0000 - val_loss: 1.7579 - val_acc: 0.5926\n",
      "Epoch 45/100\n",
      "108/108 - 2s - loss: 0.0196 - acc: 0.9907 - val_loss: 1.7232 - val_acc: 0.6296\n",
      "Epoch 46/100\n",
      "108/108 - 2s - loss: 0.0175 - acc: 1.0000 - val_loss: 1.7326 - val_acc: 0.6296\n",
      "Epoch 47/100\n",
      "108/108 - 2s - loss: 0.0193 - acc: 1.0000 - val_loss: 1.7759 - val_acc: 0.5926\n",
      "Epoch 48/100\n",
      "108/108 - 2s - loss: 0.0295 - acc: 0.9907 - val_loss: 1.9408 - val_acc: 0.5556\n",
      "Epoch 49/100\n",
      "108/108 - 2s - loss: 0.0342 - acc: 0.9815 - val_loss: 1.9182 - val_acc: 0.5556\n",
      "Epoch 50/100\n",
      "108/108 - 3s - loss: 0.0130 - acc: 1.0000 - val_loss: 1.8871 - val_acc: 0.6296\n",
      "Epoch 51/100\n",
      "108/108 - 2s - loss: 0.0135 - acc: 1.0000 - val_loss: 1.8628 - val_acc: 0.6296\n",
      "Epoch 52/100\n",
      "108/108 - 2s - loss: 0.0355 - acc: 0.9815 - val_loss: 1.8353 - val_acc: 0.6296\n",
      "Epoch 53/100\n",
      "108/108 - 2s - loss: 0.0158 - acc: 1.0000 - val_loss: 1.7860 - val_acc: 0.6296\n",
      "Epoch 54/100\n",
      "108/108 - 2s - loss: 0.0397 - acc: 0.9907 - val_loss: 1.7243 - val_acc: 0.6667\n",
      "Epoch 55/100\n",
      "108/108 - 2s - loss: 0.0330 - acc: 0.9907 - val_loss: 1.6660 - val_acc: 0.6667\n",
      "Epoch 56/100\n",
      "108/108 - 2s - loss: 0.0568 - acc: 0.9907 - val_loss: 1.6271 - val_acc: 0.6667\n",
      "Epoch 57/100\n",
      "108/108 - 2s - loss: 0.0434 - acc: 0.9815 - val_loss: 1.6961 - val_acc: 0.6296\n",
      "Epoch 58/100\n",
      "108/108 - 2s - loss: 0.0183 - acc: 1.0000 - val_loss: 1.8220 - val_acc: 0.5556\n",
      "Epoch 59/100\n",
      "108/108 - 2s - loss: 0.0483 - acc: 0.9907 - val_loss: 1.7482 - val_acc: 0.5926\n",
      "Epoch 60/100\n",
      "108/108 - 2s - loss: 0.0341 - acc: 0.9907 - val_loss: 1.6109 - val_acc: 0.6667\n",
      "Epoch 61/100\n",
      "108/108 - 2s - loss: 0.0125 - acc: 1.0000 - val_loss: 1.4732 - val_acc: 0.6667\n",
      "Epoch 62/100\n",
      "108/108 - 2s - loss: 0.0307 - acc: 0.9907 - val_loss: 1.5111 - val_acc: 0.6667\n",
      "Epoch 63/100\n",
      "108/108 - 2s - loss: 0.0290 - acc: 1.0000 - val_loss: 1.5645 - val_acc: 0.6296\n",
      "Epoch 64/100\n",
      "108/108 - 2s - loss: 0.0104 - acc: 1.0000 - val_loss: 1.6312 - val_acc: 0.6667\n",
      "Epoch 65/100\n",
      "108/108 - 2s - loss: 0.0089 - acc: 1.0000 - val_loss: 1.6813 - val_acc: 0.6667\n",
      "Epoch 66/100\n",
      "108/108 - 2s - loss: 0.0318 - acc: 0.9907 - val_loss: 1.6805 - val_acc: 0.6667\n",
      "Epoch 67/100\n",
      "108/108 - 2s - loss: 0.0360 - acc: 0.9907 - val_loss: 1.6591 - val_acc: 0.6667\n",
      "Epoch 68/100\n",
      "108/108 - 2s - loss: 0.0160 - acc: 1.0000 - val_loss: 1.6565 - val_acc: 0.6667\n",
      "Epoch 69/100\n",
      "108/108 - 2s - loss: 0.0214 - acc: 0.9907 - val_loss: 1.6727 - val_acc: 0.6667\n",
      "Epoch 70/100\n",
      "108/108 - 2s - loss: 0.0145 - acc: 0.9907 - val_loss: 1.6829 - val_acc: 0.6667\n",
      "Epoch 71/100\n",
      "108/108 - 2s - loss: 0.0131 - acc: 0.9907 - val_loss: 1.7446 - val_acc: 0.6667\n",
      "Epoch 72/100\n",
      "108/108 - 2s - loss: 0.0065 - acc: 1.0000 - val_loss: 1.7826 - val_acc: 0.6667\n",
      "Epoch 73/100\n",
      "108/108 - 2s - loss: 0.0177 - acc: 1.0000 - val_loss: 1.7811 - val_acc: 0.6667\n",
      "Epoch 74/100\n",
      "108/108 - 2s - loss: 0.0252 - acc: 0.9907 - val_loss: 1.6891 - val_acc: 0.6667\n",
      "Epoch 75/100\n",
      "108/108 - 2s - loss: 0.0104 - acc: 1.0000 - val_loss: 1.6444 - val_acc: 0.6667\n",
      "Epoch 76/100\n",
      "108/108 - 2s - loss: 0.0246 - acc: 0.9907 - val_loss: 1.6526 - val_acc: 0.6667\n",
      "Epoch 77/100\n",
      "108/108 - 2s - loss: 0.0091 - acc: 1.0000 - val_loss: 1.6621 - val_acc: 0.6667\n",
      "Epoch 78/100\n",
      "108/108 - 2s - loss: 0.0157 - acc: 0.9907 - val_loss: 1.6231 - val_acc: 0.6667\n",
      "Epoch 79/100\n",
      "108/108 - 2s - loss: 0.0091 - acc: 1.0000 - val_loss: 1.5957 - val_acc: 0.6296\n",
      "Epoch 80/100\n",
      "108/108 - 2s - loss: 0.0030 - acc: 1.0000 - val_loss: 1.5772 - val_acc: 0.6296\n",
      "Epoch 81/100\n",
      "108/108 - 2s - loss: 0.0166 - acc: 0.9907 - val_loss: 1.5211 - val_acc: 0.6667\n",
      "Epoch 82/100\n",
      "108/108 - 2s - loss: 0.0259 - acc: 0.9907 - val_loss: 1.5570 - val_acc: 0.6296\n",
      "Epoch 83/100\n",
      "108/108 - 2s - loss: 0.0050 - acc: 1.0000 - val_loss: 1.5717 - val_acc: 0.6296\n",
      "Epoch 84/100\n",
      "108/108 - 2s - loss: 0.0090 - acc: 1.0000 - val_loss: 1.5600 - val_acc: 0.6296\n",
      "Epoch 85/100\n",
      "108/108 - 2s - loss: 0.0087 - acc: 1.0000 - val_loss: 1.5534 - val_acc: 0.6296\n",
      "Epoch 86/100\n",
      "108/108 - 2s - loss: 0.0108 - acc: 1.0000 - val_loss: 1.5464 - val_acc: 0.6296\n",
      "Epoch 87/100\n",
      "108/108 - 2s - loss: 0.0017 - acc: 1.0000 - val_loss: 1.5432 - val_acc: 0.6296\n",
      "Epoch 88/100\n",
      "108/108 - 2s - loss: 0.0084 - acc: 1.0000 - val_loss: 1.5470 - val_acc: 0.6296\n",
      "Epoch 89/100\n",
      "108/108 - 2s - loss: 0.0033 - acc: 1.0000 - val_loss: 1.5502 - val_acc: 0.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "108/108 - 2s - loss: 0.0060 - acc: 1.0000 - val_loss: 1.5629 - val_acc: 0.6296\n",
      "Epoch 91/100\n",
      "108/108 - 2s - loss: 0.0062 - acc: 1.0000 - val_loss: 1.5409 - val_acc: 0.6296\n",
      "Epoch 92/100\n",
      "108/108 - 2s - loss: 0.0075 - acc: 1.0000 - val_loss: 1.5171 - val_acc: 0.6296\n",
      "Epoch 93/100\n",
      "108/108 - 2s - loss: 0.0116 - acc: 1.0000 - val_loss: 1.5141 - val_acc: 0.6296\n",
      "Epoch 94/100\n",
      "108/108 - 2s - loss: 0.0071 - acc: 1.0000 - val_loss: 1.5103 - val_acc: 0.6296\n",
      "Epoch 95/100\n",
      "108/108 - 2s - loss: 0.0141 - acc: 1.0000 - val_loss: 1.5316 - val_acc: 0.6667\n",
      "Epoch 96/100\n",
      "108/108 - 2s - loss: 0.0132 - acc: 0.9907 - val_loss: 1.4724 - val_acc: 0.6667\n",
      "Epoch 97/100\n",
      "108/108 - 2s - loss: 0.0160 - acc: 1.0000 - val_loss: 1.4180 - val_acc: 0.7037\n",
      "Epoch 98/100\n",
      "108/108 - 2s - loss: 0.0634 - acc: 0.9815 - val_loss: 1.5531 - val_acc: 0.6667\n",
      "Epoch 99/100\n",
      "108/108 - 2s - loss: 0.0239 - acc: 0.9907 - val_loss: 1.4497 - val_acc: 0.7037\n",
      "Epoch 100/100\n",
      "108/108 - 2s - loss: 0.0517 - acc: 0.9722 - val_loss: 1.2008 - val_acc: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a485dccf8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(reshaped_X2_train_scaled, y2_train, validation_split=0.2, epochs=100, shuffle=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 - 0s - loss: 0.0561 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "model_loss2, model_accuracy2 = model.evaluate(reshaped_X2_test_scaled, y2_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using test data\n",
    "predictions2 = model.predict_classes(reshaped_X2_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "two_qtrs_out = pd.DataFrame({\"Predicted\":predictions2, \"Actual\":y2_test})\n",
    "# two_qtrs_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "name2 = f\"unshuffled-2q-out-{dt.datetime.now()}\"\n",
    "model.save(f\"models/{name2}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on full X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X2_full = model.predict_classes(reshaped_X2_full)\n",
    "\n",
    "# Preview results\n",
    "X2_full_results = pd.DataFrame({\"Predicted\":pred_X2_full, \"Actual\":y2})\n",
    "# X2_full_results.loc[X2_full_results[\"Actual\"]==1]\n",
    "\n",
    "# Export results for graphing\n",
    "X2_full_results.to_csv(f\"resources/predictions/X2_full_unshuffled_{dt.datetime.now()}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix on X2-Y2 data (recession 2 quarters out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34]]\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix on X2 model\n",
    "con_mat = confusion_matrix(y2_test, predictions2)\n",
    "print(con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        34\n",
      "\n",
      "    accuracy                           1.00        34\n",
      "   macro avg       1.00      1.00      1.00        34\n",
      "weighted avg       1.00      1.00      1.00        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Score model\n",
    "print(classification_report(y2_test, predictions2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and predict on X3-Y3 data (recession 4 quarters out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 106 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "106/106 - 2s - loss: 1.0295 - acc: 0.8491 - val_loss: 0.8128 - val_acc: 0.5556\n",
      "Epoch 2/100\n",
      "106/106 - 2s - loss: 0.4787 - acc: 0.8962 - val_loss: 0.9086 - val_acc: 0.4074\n",
      "Epoch 3/100\n",
      "106/106 - 2s - loss: 0.4819 - acc: 0.8585 - val_loss: 0.9920 - val_acc: 0.4444\n",
      "Epoch 4/100\n",
      "106/106 - 2s - loss: 0.1666 - acc: 0.9245 - val_loss: 1.1620 - val_acc: 0.4815\n",
      "Epoch 5/100\n",
      "106/106 - 2s - loss: 0.2563 - acc: 0.9151 - val_loss: 1.3065 - val_acc: 0.4074\n",
      "Epoch 6/100\n",
      "106/106 - 2s - loss: 0.1476 - acc: 0.9528 - val_loss: 1.3921 - val_acc: 0.4074\n",
      "Epoch 7/100\n",
      "106/106 - 2s - loss: 0.1695 - acc: 0.9434 - val_loss: 1.2403 - val_acc: 0.4815\n",
      "Epoch 8/100\n",
      "106/106 - 2s - loss: 0.2333 - acc: 0.8962 - val_loss: 1.2374 - val_acc: 0.5556\n",
      "Epoch 9/100\n",
      "106/106 - 2s - loss: 0.1311 - acc: 0.9623 - val_loss: 1.2849 - val_acc: 0.4815\n",
      "Epoch 10/100\n",
      "106/106 - 2s - loss: 0.1346 - acc: 0.9434 - val_loss: 1.3852 - val_acc: 0.4074\n",
      "Epoch 11/100\n",
      "106/106 - 2s - loss: 0.1619 - acc: 0.9623 - val_loss: 1.4676 - val_acc: 0.3704\n",
      "Epoch 12/100\n",
      "106/106 - 2s - loss: 0.0972 - acc: 0.9623 - val_loss: 1.5798 - val_acc: 0.4444\n",
      "Epoch 13/100\n",
      "106/106 - 2s - loss: 0.0886 - acc: 0.9528 - val_loss: 1.7382 - val_acc: 0.4444\n",
      "Epoch 14/100\n",
      "106/106 - 2s - loss: 0.1115 - acc: 0.9623 - val_loss: 1.8263 - val_acc: 0.4815\n",
      "Epoch 15/100\n",
      "106/106 - 2s - loss: 0.0834 - acc: 0.9623 - val_loss: 1.8132 - val_acc: 0.4815\n",
      "Epoch 16/100\n",
      "106/106 - 2s - loss: 0.0738 - acc: 0.9717 - val_loss: 1.8933 - val_acc: 0.4815\n",
      "Epoch 17/100\n",
      "106/106 - 2s - loss: 0.0829 - acc: 0.9811 - val_loss: 2.1135 - val_acc: 0.4815\n",
      "Epoch 18/100\n",
      "106/106 - 2s - loss: 0.0713 - acc: 0.9811 - val_loss: 2.4028 - val_acc: 0.4815\n",
      "Epoch 19/100\n",
      "106/106 - 2s - loss: 0.0946 - acc: 0.9623 - val_loss: 2.4909 - val_acc: 0.4815\n",
      "Epoch 20/100\n",
      "106/106 - 2s - loss: 0.0683 - acc: 0.9623 - val_loss: 2.4666 - val_acc: 0.4074\n",
      "Epoch 21/100\n",
      "106/106 - 2s - loss: 0.0604 - acc: 0.9717 - val_loss: 2.3114 - val_acc: 0.4074\n",
      "Epoch 22/100\n",
      "106/106 - 2s - loss: 0.0461 - acc: 0.9717 - val_loss: 2.2591 - val_acc: 0.4444\n",
      "Epoch 23/100\n",
      "106/106 - 2s - loss: 0.0765 - acc: 0.9811 - val_loss: 2.2786 - val_acc: 0.4444\n",
      "Epoch 24/100\n",
      "106/106 - 2s - loss: 0.0433 - acc: 0.9906 - val_loss: 2.2528 - val_acc: 0.4444\n",
      "Epoch 25/100\n",
      "106/106 - 2s - loss: 0.0308 - acc: 1.0000 - val_loss: 2.0640 - val_acc: 0.4815\n",
      "Epoch 26/100\n",
      "106/106 - 2s - loss: 0.0595 - acc: 0.9811 - val_loss: 2.0221 - val_acc: 0.5926\n",
      "Epoch 27/100\n",
      "106/106 - 2s - loss: 0.0484 - acc: 1.0000 - val_loss: 2.2606 - val_acc: 0.5556\n",
      "Epoch 28/100\n",
      "106/106 - 2s - loss: 0.0337 - acc: 0.9906 - val_loss: 2.4389 - val_acc: 0.5556\n",
      "Epoch 29/100\n",
      "106/106 - 2s - loss: 0.0385 - acc: 0.9906 - val_loss: 2.4756 - val_acc: 0.5556\n",
      "Epoch 30/100\n",
      "106/106 - 2s - loss: 0.0482 - acc: 0.9811 - val_loss: 2.2183 - val_acc: 0.6667\n",
      "Epoch 31/100\n",
      "106/106 - 2s - loss: 0.0318 - acc: 0.9906 - val_loss: 2.4191 - val_acc: 0.6667\n",
      "Epoch 32/100\n",
      "106/106 - 2s - loss: 0.0455 - acc: 0.9717 - val_loss: 2.2851 - val_acc: 0.6667\n",
      "Epoch 33/100\n",
      "106/106 - 2s - loss: 0.0536 - acc: 0.9811 - val_loss: 2.1420 - val_acc: 0.6667\n",
      "Epoch 34/100\n",
      "106/106 - 2s - loss: 0.0215 - acc: 0.9906 - val_loss: 2.1690 - val_acc: 0.5926\n",
      "Epoch 35/100\n",
      "106/106 - 2s - loss: 0.0386 - acc: 0.9906 - val_loss: 2.3847 - val_acc: 0.5926\n",
      "Epoch 36/100\n",
      "106/106 - 2s - loss: 0.0367 - acc: 0.9811 - val_loss: 2.5912 - val_acc: 0.4815\n",
      "Epoch 37/100\n",
      "106/106 - 2s - loss: 0.0371 - acc: 0.9811 - val_loss: 2.4011 - val_acc: 0.5926\n",
      "Epoch 38/100\n",
      "106/106 - 2s - loss: 0.0283 - acc: 0.9811 - val_loss: 2.4327 - val_acc: 0.6296\n",
      "Epoch 39/100\n",
      "106/106 - 2s - loss: 0.0908 - acc: 0.9906 - val_loss: 2.4907 - val_acc: 0.5556\n",
      "Epoch 40/100\n",
      "106/106 - 2s - loss: 0.1624 - acc: 0.9528 - val_loss: 2.9108 - val_acc: 0.5185\n",
      "Epoch 41/100\n",
      "106/106 - 2s - loss: 0.1936 - acc: 0.8962 - val_loss: 2.8639 - val_acc: 0.3333\n",
      "Epoch 42/100\n",
      "106/106 - 2s - loss: 0.1287 - acc: 0.9434 - val_loss: 3.0655 - val_acc: 0.3333\n",
      "Epoch 43/100\n",
      "106/106 - 2s - loss: 0.1689 - acc: 0.9151 - val_loss: 3.5749 - val_acc: 0.3333\n",
      "Epoch 44/100\n",
      "106/106 - 2s - loss: 0.0890 - acc: 0.9623 - val_loss: 3.5664 - val_acc: 0.2593\n",
      "Epoch 45/100\n",
      "106/106 - 2s - loss: 0.0880 - acc: 0.9434 - val_loss: 3.3901 - val_acc: 0.2222\n",
      "Epoch 46/100\n",
      "106/106 - 2s - loss: 0.0990 - acc: 0.9717 - val_loss: 2.7818 - val_acc: 0.3333\n",
      "Epoch 47/100\n",
      "106/106 - 2s - loss: 0.0820 - acc: 0.9717 - val_loss: 2.2433 - val_acc: 0.2593\n",
      "Epoch 48/100\n",
      "106/106 - 2s - loss: 0.0872 - acc: 0.9717 - val_loss: 2.1016 - val_acc: 0.4815\n",
      "Epoch 49/100\n",
      "106/106 - 2s - loss: 0.0343 - acc: 1.0000 - val_loss: 2.2723 - val_acc: 0.5556\n",
      "Epoch 50/100\n",
      "106/106 - 2s - loss: 0.0354 - acc: 0.9906 - val_loss: 2.4942 - val_acc: 0.5185\n",
      "Epoch 51/100\n",
      "106/106 - 2s - loss: 0.0435 - acc: 0.9717 - val_loss: 2.7489 - val_acc: 0.4444\n",
      "Epoch 52/100\n",
      "106/106 - 2s - loss: 0.0375 - acc: 0.9906 - val_loss: 2.9304 - val_acc: 0.4074\n",
      "Epoch 53/100\n",
      "106/106 - 2s - loss: 0.0234 - acc: 1.0000 - val_loss: 3.1188 - val_acc: 0.3333\n",
      "Epoch 54/100\n",
      "106/106 - 3s - loss: 0.0490 - acc: 0.9717 - val_loss: 3.1468 - val_acc: 0.3704\n",
      "Epoch 55/100\n",
      "106/106 - 2s - loss: 0.0131 - acc: 1.0000 - val_loss: 3.2717 - val_acc: 0.3704\n",
      "Epoch 56/100\n",
      "106/106 - 2s - loss: 0.0618 - acc: 0.9811 - val_loss: 3.0378 - val_acc: 0.3704\n",
      "Epoch 57/100\n",
      "106/106 - 2s - loss: 0.0233 - acc: 1.0000 - val_loss: 2.3518 - val_acc: 0.4815\n",
      "Epoch 58/100\n",
      "106/106 - 3s - loss: 0.0211 - acc: 1.0000 - val_loss: 2.5768 - val_acc: 0.3704\n",
      "Epoch 59/100\n",
      "106/106 - 2s - loss: 0.0182 - acc: 1.0000 - val_loss: 2.5526 - val_acc: 0.3704\n",
      "Epoch 60/100\n",
      "106/106 - 2s - loss: 0.0213 - acc: 1.0000 - val_loss: 2.2828 - val_acc: 0.4074\n",
      "Epoch 61/100\n",
      "106/106 - 2s - loss: 0.0116 - acc: 1.0000 - val_loss: 2.0612 - val_acc: 0.5185\n",
      "Epoch 62/100\n",
      "106/106 - 2s - loss: 0.0077 - acc: 1.0000 - val_loss: 2.0486 - val_acc: 0.4815\n",
      "Epoch 63/100\n",
      "106/106 - 2s - loss: 0.0244 - acc: 0.9906 - val_loss: 2.0346 - val_acc: 0.4815\n",
      "Epoch 64/100\n",
      "106/106 - 2s - loss: 0.0079 - acc: 1.0000 - val_loss: 2.0600 - val_acc: 0.4815\n",
      "Epoch 65/100\n",
      "106/106 - 2s - loss: 0.0110 - acc: 1.0000 - val_loss: 2.1063 - val_acc: 0.4815\n",
      "Epoch 66/100\n",
      "106/106 - 2s - loss: 0.0226 - acc: 0.9906 - val_loss: 2.2237 - val_acc: 0.4815\n",
      "Epoch 67/100\n",
      "106/106 - 2s - loss: 0.0364 - acc: 0.9811 - val_loss: 2.4189 - val_acc: 0.4815\n",
      "Epoch 68/100\n",
      "106/106 - 2s - loss: 0.0530 - acc: 0.9906 - val_loss: 2.5979 - val_acc: 0.4815\n",
      "Epoch 69/100\n",
      "106/106 - 2s - loss: 0.0280 - acc: 0.9906 - val_loss: 2.4098 - val_acc: 0.5185\n",
      "Epoch 70/100\n",
      "106/106 - 2s - loss: 0.0463 - acc: 0.9906 - val_loss: 2.6071 - val_acc: 0.4815\n",
      "Epoch 71/100\n",
      "106/106 - 2s - loss: 0.0078 - acc: 1.0000 - val_loss: 3.5821 - val_acc: 0.3333\n",
      "Epoch 72/100\n",
      "106/106 - 2s - loss: 0.0478 - acc: 0.9811 - val_loss: 3.4210 - val_acc: 0.3704\n",
      "Epoch 73/100\n",
      "106/106 - 2s - loss: 0.0218 - acc: 0.9906 - val_loss: 2.7457 - val_acc: 0.3333\n",
      "Epoch 74/100\n",
      "106/106 - 2s - loss: 0.0051 - acc: 1.0000 - val_loss: 2.3132 - val_acc: 0.4444\n",
      "Epoch 75/100\n",
      "106/106 - 2s - loss: 0.0090 - acc: 1.0000 - val_loss: 1.9753 - val_acc: 0.4444\n",
      "Epoch 76/100\n",
      "106/106 - 2s - loss: 0.0063 - acc: 1.0000 - val_loss: 1.8592 - val_acc: 0.5185\n",
      "Epoch 77/100\n",
      "106/106 - 2s - loss: 0.0223 - acc: 0.9906 - val_loss: 2.0448 - val_acc: 0.4444\n",
      "Epoch 78/100\n",
      "106/106 - 2s - loss: 0.0045 - acc: 1.0000 - val_loss: 2.4817 - val_acc: 0.4074\n",
      "Epoch 79/100\n",
      "106/106 - 3s - loss: 0.0251 - acc: 0.9906 - val_loss: 1.9797 - val_acc: 0.5556\n",
      "Epoch 80/100\n",
      "106/106 - 2s - loss: 0.0031 - acc: 1.0000 - val_loss: 1.8542 - val_acc: 0.5556\n",
      "Epoch 81/100\n",
      "106/106 - 2s - loss: 0.0112 - acc: 1.0000 - val_loss: 1.8484 - val_acc: 0.5556\n",
      "Epoch 82/100\n",
      "106/106 - 2s - loss: 0.0069 - acc: 1.0000 - val_loss: 1.8599 - val_acc: 0.5556\n",
      "Epoch 83/100\n",
      "106/106 - 2s - loss: 0.0064 - acc: 1.0000 - val_loss: 1.8918 - val_acc: 0.5556\n",
      "Epoch 84/100\n",
      "106/106 - 2s - loss: 0.0116 - acc: 1.0000 - val_loss: 2.2509 - val_acc: 0.4815\n",
      "Epoch 85/100\n",
      "106/106 - 2s - loss: 0.0377 - acc: 0.9811 - val_loss: 2.1259 - val_acc: 0.5185\n",
      "Epoch 86/100\n",
      "106/106 - 2s - loss: 0.0034 - acc: 1.0000 - val_loss: 2.1126 - val_acc: 0.5556\n",
      "Epoch 87/100\n",
      "106/106 - 2s - loss: 0.0152 - acc: 0.9906 - val_loss: 2.1442 - val_acc: 0.5556\n",
      "Epoch 88/100\n",
      "106/106 - 2s - loss: 0.0069 - acc: 1.0000 - val_loss: 2.1088 - val_acc: 0.5556\n",
      "Epoch 89/100\n",
      "106/106 - 2s - loss: 0.0100 - acc: 1.0000 - val_loss: 2.1000 - val_acc: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "106/106 - 2s - loss: 0.0204 - acc: 0.9906 - val_loss: 2.1752 - val_acc: 0.5556\n",
      "Epoch 91/100\n",
      "106/106 - 2s - loss: 0.0126 - acc: 1.0000 - val_loss: 2.4613 - val_acc: 0.5185\n",
      "Epoch 92/100\n",
      "106/106 - 2s - loss: 0.0092 - acc: 1.0000 - val_loss: 2.7232 - val_acc: 0.4444\n",
      "Epoch 93/100\n",
      "106/106 - 2s - loss: 0.0102 - acc: 1.0000 - val_loss: 2.8377 - val_acc: 0.4444\n",
      "Epoch 94/100\n",
      "106/106 - 2s - loss: 0.0145 - acc: 1.0000 - val_loss: 2.6451 - val_acc: 0.4815\n",
      "Epoch 95/100\n",
      "106/106 - 2s - loss: 0.0105 - acc: 1.0000 - val_loss: 2.2842 - val_acc: 0.4815\n",
      "Epoch 96/100\n",
      "106/106 - 2s - loss: 0.0034 - acc: 1.0000 - val_loss: 2.0421 - val_acc: 0.4815\n",
      "Epoch 97/100\n",
      "106/106 - 2s - loss: 0.0041 - acc: 1.0000 - val_loss: 1.8979 - val_acc: 0.5556\n",
      "Epoch 98/100\n",
      "106/106 - 2s - loss: 0.0101 - acc: 1.0000 - val_loss: 1.8491 - val_acc: 0.5556\n",
      "Epoch 99/100\n",
      "106/106 - 2s - loss: 0.0042 - acc: 1.0000 - val_loss: 1.8429 - val_acc: 0.5556\n",
      "Epoch 100/100\n",
      "106/106 - 2s - loss: 0.0094 - acc: 1.0000 - val_loss: 1.9031 - val_acc: 0.4815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4dc32c50>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(reshaped_X3_train_scaled, y3_train, validation_split=0.2, epochs=100, shuffle=False, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 - 0s - loss: 4.7858 - acc: 0.3529\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using test data\n",
    "model_loss3, model_accuracy3 = model.evaluate(reshaped_X3_test_scaled, y3_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using test data\n",
    "predictions3 = model.predict_classes(reshaped_X3_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "four_qtrs_out = pd.DataFrame({\"Predicted\":predictions3, \"Actual\":y3_test})\n",
    "# four_qtrs_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "name3 = f\"unshuffled-4q-out-{dt.datetime.now()}\"\n",
    "model.save(f\"models/{name3}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict on full X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_X3_full = model.predict_classes(reshaped_X3_full)\n",
    "\n",
    "# Preview results\n",
    "X3_full_results = pd.DataFrame({\"Predicted\":pred_X3_full, \"Actual\":y3})\n",
    "# X3_full_results.loc[X3_full_results[\"Actual\"]==1]\n",
    "\n",
    "# Export results for graphing\n",
    "X3_full_results.to_csv(f\"resources/predictions/X3_full_unshuffled_{dt.datetime.now()}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix on X3-Y3 data (recession 4 quarters out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12 22]\n",
      " [ 0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix on X3 model\n",
    "con_mat = confusion_matrix(y3_test, predictions3)\n",
    "print(con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.35      0.52        34\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.35        34\n",
      "   macro avg       0.50      0.18      0.26        34\n",
      "weighted avg       1.00      0.35      0.52        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Score model\n",
    "print(classification_report(y3_test, predictions3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on 2019 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019Q1: 1 Quarter Out\n",
    "\n",
    "# 2019Q1: 2 Quarters Out\n",
    "\n",
    "# 2019Q1: 4 Quarters Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019Q2: 1 Quarter Out\n",
    "\n",
    "# 2019Q2: 2 Quarters Out\n",
    "\n",
    "# 2019Q2: 4 Quarters Out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
